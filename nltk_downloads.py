# Downloading the relevant files

import nltk

# Getting the sample tweets
nltk.download('twitter_samples')

# Downloading a tokenizer
nltk.download('punkt')

# Stemming 

# Wordnet helps determine the base of a word
nltk.download('wordnet')

# Context of a word in a sentence
nltk.download('averaged_perceptron_tagger')

# Stop words
nltk.download('stopwords')
